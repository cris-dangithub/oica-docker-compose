# OICA - Sistema de Optimizaci√≥n con PostgreSQL y Procesamiento As√≠ncrono

## üöÄ Arquitectura del Sistema

El sistema ha sido migrado de localStorage a PostgreSQL con procesamiento as√≠ncrono:

- **Frontend**: Next.js 15 con Socket.IO para actualizaciones en tiempo real
- **Backend**: Flask + SQLAlchemy con WebSocket
- **Base de Datos**: PostgreSQL 15 con esquema normalizado
- **Cola de Tareas**: Celery + Redis para procesamiento as√≠ncrono
- **Almacenamiento**: Directorios UUID para aislamiento de versiones

## üìã Requisitos Previos

- Docker y Docker Compose
- Node.js 18+ (para desarrollo local del frontend)
- Puertos disponibles: 3000 (frontend), 5000 (backend), 5432 (PostgreSQL), 6379 (Redis)

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### 1. Clonar y preparar el proyecto

```bash
cd /home/cris/projects/01-proyecto_de_grado/oica-docker-compose
```

### 2. Instalar dependencias del frontend

```bash
cd services/frontend
npm install
cd ../..
```

### 3. Levantar servicios con Docker Compose

```bash
docker-compose up --build
```

Esto iniciar√°:
- **db**: PostgreSQL con schema autom√°tico (puerto 5432)
- **redis**: Redis para Celery (puerto 6379)
- **backend**: Flask server (puerto 5000)
- **celery_worker**: Worker para procesamiento as√≠ncrono
- **frontend**: Next.js (puerto 3000)

### 4. Verificar que todos los servicios est√©n saludables

```bash
# Verificar estado de contenedores
docker-compose ps

# Ver logs del backend
docker-compose logs -f backend

# Ver logs del worker
docker-compose logs -f celery_worker
```

## üß™ Flujo de Prueba Completo

### Paso 1: Acceder a la aplicaci√≥n

Abrir navegador en: `http://localhost:3000`

### Paso 2: Subir archivo de prueba

1. Ir a "SUBIR CARTILLA" en el navbar
2. Seleccionar archivo XLSX o CSV con formato esperado:
   - Columnas: `id_pedido`, `numero_barra`, `longitud_pieza_requerida`, `cantidad_requerida`, `grupo_ejecucion`
3. Ingresar n√∫mero de documento (ej: "12345")
4. Seleccionar perfil de optimizaci√≥n:
   - **Econom√≠a**: M√°s ahorro de material, procesamiento m√°s lento
   - **Balanceado**: Equilibrio entre velocidad y ahorro (recomendado)
   - **Velocidad**: Procesamiento r√°pido, menor optimizaci√≥n
5. Click en "Enviar"

### Paso 3: Observar procesamiento en tiempo real

La UI mostrar√°:
- Barra de progreso actualizada en tiempo real v√≠a WebSocket
- Estados: Cargado ‚Üí Validando ‚Üí Validado ‚Üí Procesando ‚Üí Generando ‚Üí Completado
- Progreso: 0% ‚Üí 10% ‚Üí 20% ‚Üí 70% ‚Üí 75% ‚Üí 100%

### Paso 4: Ver archivos procesados

1. Ir a "ARCHIVOS" en el navbar
2. Tabla con todos los archivos cargados
3. Filtros disponibles:
   - **B√∫squeda**: Por nombre de archivo o n√∫mero de documento
   - **Estado**: uploaded, processing, completed, error_*
   - **Perfil**: economia, balanceado, velocidad
   - **Rango de fechas**: Desde/Hasta

### Paso 5: Descargar resultados

Para cada archivo completado:
- **Bot√≥n Excel**: Descarga `resultados_optimizacion.xlsx`
- **Bot√≥n PDF**: Descarga `plan_de_corte.pdf` con plantilla HTML formateada
- **Bot√≥n IMG**: Descarga `grafica_cortes.png` con visualizaci√≥n de barras

### Paso 6: Reprocesar con diferente perfil

1. Click en bot√≥n "Reprocesar" (icono de refresh)
2. Seleccionar nuevo perfil
3. Se crear√° nueva versi√≥n manteniendo versiones anteriores

### Paso 7: Eliminar archivos

1. Click en bot√≥n "Eliminar" (icono de papelera)
2. Confirmar eliminaci√≥n
3. Se borran:
   - Registro en base de datos (uploaded_files + processing_results CASCADE)
   - Directorios UUID del filestore
   - Archivo temporal original

## üìä Validaciones del Sistema

El sistema valida autom√°ticamente:

1. **Formato de archivo**: Solo XLSX y CSV
2. **Columnas requeridas**: 5 columnas esenciales
3. **Tipos de datos**: 
   - `longitud_pieza_requerida`: num√©rico
   - `cantidad_requerida`: num√©rico entero positivo
   - `masa_unitaria_kg`: num√©rico (si existe)
4. **Rangos de valores**:
   - Longitud: 0.1m - 100m
   - Cantidad: 1 - 10000 unidades
5. **Valores positivos**: No acepta negativos ni ceros

**Comportamiento en errores**:
- Estado cambia a `error_validation`, `error_processing` o `error_generation`
- Mensaje de error detallado en campo `status_details`
- No se generan artefactos incompletos

## üóÑÔ∏è Estructura de la Base de Datos

### Tabla: `uploaded_files`
```sql
- id (PK)
- filename
- document_number
- perfil (economia | balanceado | velocidad)
- uploaded_file_path
- status (uploaded, validating, processing, completed, error_*)
- status_details (JSONB)
- created_at, updated_at
```

### Tabla: `processing_results`
```sql
- id (PK)
- uploaded_file_id (FK)
- version_number (1, 2, 3...)
- storage_uuid (UUID v4)
- resultados_df (JSONB con DataFrame)
- metricas (JSONB con estad√≠sticas)
- excel_path, pdf_path, image_path
- status, status_details
- created_at, updated_at
```

**Relaci√≥n**: 1 UploadedFile ‚Üí N ProcessingResults (versionamiento)

## üîß Arquitectura del Procesamiento As√≠ncrono

```
Cliente                Backend                 Celery Worker
  |                       |                           |
  | POST /upload          |                           |
  |--------------------->|                           |
  |                       | Guarda archivo temp       |
  |                       | Crea UploadedFile         |
  |                       | Encola tarea              |
  |<---------------------|                           |
  | {task_id, file_id}    |                           |
  |                       |                           |
  | subscribe_task        |                           |
  |--------------------->|                           |
  |                       | apply_async               |
  |                       |------------------------->|
  |                       |                           | 1. Validating (10%)
  |                       |                           | 2. Validated (20%)
  |                       |                           | 3. Processing (20-70%)
  |                       |                           | 4. Generating (75%)
  |                       |                           | 5. Completed (100%)
  |<------ task_update ---|<------ update_state ------|
  | {state, progress}     |                           |
```

## üìÅ Estructura de Almacenamiento

```
data/filestore/
‚îú‚îÄ‚îÄ temp/                          # Archivos temporales subidos
‚îÇ   ‚îî‚îÄ‚îÄ 1234567890.123_cartilla.xlsx
‚îî‚îÄ‚îÄ {uuid}/                        # Directorio por versi√≥n
    ‚îú‚îÄ‚îÄ resultados_optimizacion.xlsx
    ‚îú‚îÄ‚îÄ plan_de_corte.pdf
    ‚îî‚îÄ‚îÄ grafica_cortes.png
```

Cada reprocesamiento crea un nuevo UUID aislado.

## üîç Endpoints de la API

### HTTP Endpoints

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| POST | `/upload` | Sube archivo y encola procesamiento |
| GET | `/files` | Lista archivos con filtros y paginaci√≥n |
| GET | `/file/<id>` | Detalle de archivo con todas sus versiones |
| DELETE | `/file/<id>` | Elimina archivo y todas sus versiones |
| POST | `/reprocess/<id>` | Reprocesa archivo con nuevo perfil |
| GET | `/descargar-excel/<uuid>` | Descarga Excel de resultados |
| GET | `/descargar-pdf/<uuid>` | Descarga PDF con plan de corte |
| GET | `/descargar-imagen/<uuid>` | Descarga imagen PNG de gr√°fica |
| GET | `/health` | Health check (verifica conexi√≥n BD) |

### WebSocket Events

| Evento | Direcci√≥n | Descripci√≥n |
|--------|-----------|-------------|
| `connect` | Cliente ‚Üí Server | Cliente se conecta |
| `connected` | Server ‚Üí Cliente | Confirmaci√≥n de conexi√≥n |
| `subscribe_task` | Cliente ‚Üí Server | Suscripci√≥n a tarea espec√≠fica |
| `subscribed` | Server ‚Üí Cliente | Confirmaci√≥n de suscripci√≥n |
| `task_update` | Server ‚Üí Cliente | Actualizaci√≥n de estado y progreso |

## üêõ Troubleshooting

### Backend no inicia

```bash
# Ver logs del backend
docker-compose logs backend

# Verificar conexi√≥n a PostgreSQL
docker-compose exec backend python -c "from models import db; print(db)"
```

### Celery worker no procesa tareas

```bash
# Ver logs del worker
docker-compose logs celery_worker

# Verificar conexi√≥n a Redis
docker-compose exec backend redis-cli -h redis ping
```

### WebSocket no conecta

```bash
# Verificar en consola del navegador
# Debe mostrar: [Socket.IO] Conectado al servidor

# Verificar variable de entorno
echo $NEXT_PUBLIC_API_URL
```

### Base de datos no inicializa

```bash
# Conectar a PostgreSQL
docker-compose exec db psql -U oica_user -d oica_db

# Verificar tablas
\dt

# Deber√≠a mostrar: uploaded_files, processing_results
```

## üîÑ Reiniciar el Sistema

```bash
# Detener servicios
docker-compose down

# Limpiar vol√∫menes (BORRA TODOS LOS DATOS)
docker-compose down -v

# Reconstruir e iniciar
docker-compose up --build
```

## üìù Variables de Entorno

### Backend (.env o docker-compose.yaml)
```bash
DATABASE_URL=postgresql://oica_user:oica_password@db:5432/oica_db
REDIS_URL=redis://redis:6379/0
SECRET_KEY=change-this-in-production
FLASK_DEBUG=False
```

### Frontend (.env.local)
```bash
NEXT_PUBLIC_API_URL=http://localhost:5000
```

## üéØ Caracter√≠sticas Implementadas

‚úÖ Migraci√≥n completa de localStorage a PostgreSQL  
‚úÖ Procesamiento as√≠ncrono con Celery + Redis  
‚úÖ WebSocket para actualizaciones en tiempo real  
‚úÖ Versionamiento de resultados con UUIDs  
‚úÖ Validaci√≥n de contenido con 5 reglas  
‚úÖ 4 filtros en tabla de archivos  
‚úÖ 3 botones de descarga por archivo  
‚úÖ Reprocesamiento con diferentes perfiles  
‚úÖ Eliminaci√≥n completa (BD + filestore)  
‚úÖ Estados granulares (8 estados)  
‚úÖ Barra de progreso en tiempo real  
‚úÖ Paginaci√≥n de resultados  
‚úÖ Sistema single-user sin autenticaci√≥n  

## üìö Documentaci√≥n Adicional

- **Prompt de Especificaci√≥n**: `tmp/prompt.md`
- **C√≥digo Antiguo**: `services/backend/main.py`, `services/backend/server_old.py`
- **Schema SQL**: `config/backend/init.sql`
- **Modelos ORM**: `services/backend/models/uploaded_file.py`
- **Worker Celery**: `services/backend/celery_worker.py`
- **Cliente WebSocket**: `services/frontend/src/lib/socket.ts`

## ü§ù Contacto y Soporte

Para dudas o problemas, revisar logs en:
```bash
docker-compose logs -f backend
docker-compose logs -f celery_worker
```
